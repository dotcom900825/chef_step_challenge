<div class='container'>
  <div class='text-center logo'>
    <%= image_tag "logo.png", :width=>200%>
  </div>

  <div class='row'>
    <div class='col-md-4'>
      <h3>Question lists</h3>

      <ul class="list-group">
        <li class="list-group-item"><a href="#/">Q1</a></li>
        <li class="list-group-item"><a href="#/q2">Q2</a></li>
        <li class="list-group-item"><a href="#/q3">Q3</a></li>
        <li class="list-group-item"><a href="#/q4">Q4</a></li>
        <li class="list-group-item"><a href="#/worker">Q5: worker.rb</a> </li>
        <li class="list-group-item"><a href="#/single_thread_solution">Q5: single_thread.rb</a></li>
        <li class="list-group-item active"><a href="#/multi_threaded_solution">Q5: multi_thread.rb</a></li>
        <li class="list-group-item"><a href="#/discussion">Q5: Discussion</a></li>
      </ul>
    </div>

    <div class='col-md-8'>
      <h4 class='code-header-first'>Multi-threads solution</h4>
      <section class='answer'>
        Here is the code snippet for multi-threads solution. I used 20 threads in the following solution to help process the email array containing one million records, each thread will help process a sub array of size 50000. I used a simple hash function for preprocessing, make sure all the same duplicated emails are mapped to the same worker to avoid duplicate emails emerging again from different workers after the processing. 
        <hr>
        One small issue here is that if the data set has 50% randomly placed duplicates email, then my solution will overburden one worker thread a lot. For example, say we have 1000 emails in total, and 500 of them are duplicates, when we map the data to 5 workers, 4 of them have around 100 emails to process, but one of them has around 600 emails to process due to the duplication emails all get mapped to the same worker. 
        <hr>
        To tackle this issue, we can set a threshold for each worker, the simplest one might be the (total email size /  worker size). Before the worker starts executing, it can check its array size with the threshold value, if the size is bigger then the threshold value, then it can break its array into evenly sized array chunks and spawn some additional threads to process those chunks. Once all the threads finished executing, we can join the results and remove duplicates again as the final result for the overburdened worker.
        <hr>
        This can better leverage multi-core environments but might not be too practical.
        A more plausible way might be by maintaining an LRU hash map in memory, when there is new email address shows up and the hash map still has the space, we store it into the hashmap. Otherwise, we expel the least recent record and pop in the new one. For each email address, we check if it exists in hashmap already or not. If is not, we calculate its hash value and map it into a worker. In this way, we can help reduce the amount of emails each worker needs to process, especially the burdened worker. The effectiveness depends on the size of the hashmap we can have in the memory.
      </section>

      <snippet>
  require "benchmark"
  require "faker"
  require "./worker.rb"

  worker_size = 20
  email_array = []
  output = []
  duplicate_email = Faker::Internet.email

  500000.times do 
    random_email = Faker::Internet.email
    while random_email != duplicate_email
      email_array << random_email
      break    
    end
    email_array << duplicate_email
  end

  test_array = email_array.shuffle

  chunked_array = Array.new(worker_size) {[]}
  test_array.each do |email|
    hash = email.hash
    chunked_array[hash % worker_size] << email
  end

  worker_array = []

  Benchmark.bm do |bm| 
    bm.report do 
      threads = chunked_array.each do |sub_array|
        Thread.new do
          worker = Worker.new(sub_array)
          worker_array << worker
          worker.remove_duplicates
        end
      end

      threads.each {|thr| thr.join}
      worker_array.map {|worker| output << worker.array}
      output.flatten!
    end
  end
      </snippet>
    </div>
  </div>
</div>